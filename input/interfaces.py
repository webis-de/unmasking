# General-purpose unmasking framework
# Copyright (C) 2017 Janek Bevendorff, Webis Group
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation
# files (the "Software"), to deal in the Software without
# restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
# OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
# HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
# OTHER DEALINGS IN THE SOFTWARE.

from conf.interfaces import path_property
from conf.interfaces import Configurable
from util.util import lru_cache, get_base_path

from abc import ABCMeta, abstractmethod
from enum import Enum, unique
from typing import AsyncGenerator, Iterable, List
from uuid import UUID

import os


class Tokenizer(Configurable, metaclass=ABCMeta):
    """
    Base class for tokenizers.

    Tokenizer properties with setters defined via @property.setter
    can be set at runtime via job configuration.
    """

    @abstractmethod
    def tokenize(self, text: str) -> Iterable[str]:
        """
        Tokenize given input text.

        This method will be called a lot and should therefore be as fast as possible.
        If your tokenizer creates deterministic tokens, you should therefore consider returning
        cached results by this method into :function:: util.util.lru_cache().

        :param text: input text
        :return: Iterable of tokens generated from ``text`` (may be a generator)
        """
        pass

    async def await_tokens(self, text: str) -> AsyncGenerator[str, None]:
        """
        Return async generator for the tokens generated by :meth:: tokenize().

        :param text: input text
        :return: async generator for tokens generated from ``text``
        """
        for t in self.tokenize(text):
            yield t


class Chunker(Configurable, metaclass=ABCMeta):
    """
    Base class for chunkers.

    Tokenizer properties with setters defined via @property.setter
    can be set at runtime via job configuration.
    """
    def __init__(self, chunk_size: int = 500):
        """
        :param chunk_size: maximum chunk size
        """
        self._chunk_size = chunk_size

    @abstractmethod
    def chunk(self, text: str) -> Iterable[str]:
        """
        Chunk a given text into several smaller texts.

        This method will be called a lot and should therefore be as fast as possible.
        If your chunker creates deterministic tokens, you should therefore consider returning
        cached results by this method into :function:: util.util.lru_cache().

        :param text: input text
        :return: Iterable of tokens chunks from ``text`` (may be a generator)
        """
        pass

    async def await_chunks(self, text: str) -> AsyncGenerator[str, None]:
        """
        Return async generator for the chunks generated by :meth:: chunk().

        :param text: input text
        :return: async generator for chunks generated from ``text``
        """
        for t in self.chunk(text):
            yield t

    @property
    def chunk_size(self) -> int:
        """Get chunk size"""
        return self._chunk_size

    @chunk_size.setter
    def chunk_size(self, chunk_size: int):
        """Set chunk size"""
        self._chunk_size = chunk_size


@unique
class SamplePairClass(Enum):
    """
    Base enumeration type for pairs. Members designating specific pair classes can be
    defined in sub-types of this enum type.
    """

    def __repr__(self):
        return self.name

    def __str__(self):
        return self.__repr__()

    def __eq__(self, other):
        if other is None and self.value == -1:
            return True
        elif isinstance(other, self.__class__):
            return other.value == self.value
        elif isinstance(other, str):
            return other.upper() == self.__str__()
        elif isinstance(other, int):
            return other == self.value
        elif isinstance(other, bool):
            if self.value == -1:
                return False
            else:
                return bool(self.value) == other

    def __hash__(self):
        return self.__repr__().__hash__()


class SamplePair(metaclass=ABCMeta):
    """
    Pair of sample text sets.

    Events published by this class:

    * `onProgress`:          [type ProgressEvent]
                             fired to indicate pair chunking progress
    """

    SAMPLE_PAIR_NS = UUID("412bd9f0-4c61-4bb7-a7f2-c88be2f9555c")

    def __init__(self, cls: SamplePairClass, chunker: Chunker):
        """
        Initialize pair of sample texts. Expects a set of main texts ``a`` and one
        or more texts ``b`` to compare with.
        Texts in ``a`` and ``b`` will be chunked individually before adding them
        sequentially to the chunk list.

        :param a: list of texts to verify
        :param b: list of other texts to compare with
        :param cls: class of the pair
        :param chunker: chunker for splitting input text
        """
        self._cls = cls
        self._chunker = chunker

    @abstractmethod
    def chunk(self, a: List[str], b: List[str]):
        """
        Create chunks from inputs.

        :param a: input texts one
        :param b: input texts two
        """
        pass

    @property
    @abstractmethod
    def cls(self) -> SamplePairClass:
        """Class (same author|different authors|unspecified)"""
        pass

    @property
    @abstractmethod
    def pair_id(self) -> str:
        """UUID string identifying a pair based on its set of texts."""
        pass

    @property
    @abstractmethod
    def chunks_a(self) -> List[str]:
        """Chunks of first text (text to verify)"""
        pass

    @property
    @abstractmethod
    def chunks_b(self) -> List[str]:
        """Chunks of texts to compare the first text (a) with"""
        pass


class CorpusParser(Configurable, metaclass=ABCMeta):
    """
    Base class for corpus parsers.
    """

    def __init__(self, chunk_tokenizer: Tokenizer, corpus_path: str = None):
        """
        :param corpus_path: path to the corpus directory
        :param chunk_tokenizer: chunk tokenizer
        """
        self._corpus_path = None
        self.corpus_path = corpus_path
        self.chunk_tokenizer = chunk_tokenizer

    @path_property
    def corpus_path(self) -> str:
        """Get corpus path"""
        return self._corpus_path

    @corpus_path.setter
    def corpus_path(self, path: str):
        """Set corpus path"""
        if path is not None:
            self._corpus_path = os.path.join(get_base_path(), path)
        else:
            self._corpus_path = None

    @abstractmethod
    async def __aiter__(self) -> AsyncGenerator[SamplePair, None]:
        """
        Asynchronous generator for parsed SamplePairs.
        """
        pass

    async def await_file(self, file_name) -> str:
        """
        Caching helper coroutine for reading a file.

        :param file_name: name of the file
        :return: its contents
        """
        return self.read_file(file_name)

    @lru_cache(protected=True, maxsize=50)
    def read_file(self, file_name) -> str:
        """
        Caching helper method for reading a file.

        :param file_name: name of the file
        :return: its contents
        """
        with open(file_name, "r", encoding="utf-8", errors="ignore") as f:
            return f.read().replace("\ufeff", "")

    async def await_lines(self, file_name) -> AsyncGenerator[str, None]:
        """
        Read file line by line.

        :param file_name: name of the file
        :return: its contents line by line
        """
        with open(file_name, "r", encoding="utf-8", errors="ignore") as f:
            first = True
            for line in f:
                if first and line.startswith("\ufeff"):
                    yield line.replace("\ufeff", "")
                    first = False
                else:
                    yield line
